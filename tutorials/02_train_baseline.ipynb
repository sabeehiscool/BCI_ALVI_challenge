{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Baseline\n",
    "\n",
    "This notebook shows how to train the baseline model for this competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from utils.train import TrainConfig, run_train_model\n",
    "from utils.augmentations import get_default_transform\n",
    "from utils import creating_dataset\n",
    "\n",
    "# this is the implementation of the custom baseline model\n",
    "from utils import hvatnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define trainer configuration\n",
    "\n",
    "The `TrainConfig` class is used to train the baseline model - have a look at the parameters it has!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = TrainConfig(exp_name='test_2_run_fedya', p_augs=0.3, batch_size=64, eval_interval=150, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting val datasets\n",
      "Number of moves: 72 | Dataset: fedya_tropin_standart_elbow_left\n",
      "Reorder this dataset fedya_tropin_standart_elbow_left True\n",
      "Getting train datasets\n",
      "Number of moves: 72 | Dataset: fedya_tropin_standart_elbow_left\n",
      "Reorder this dataset fedya_tropin_standart_elbow_left True\n",
      "Number of moves: 70 | Dataset: valery_first_standart_elbow_left\n",
      "Reorder this dataset valery_first_standart_elbow_left True\n",
      "Number of moves: 135 | Dataset: alex_kovalev_standart_elbow_left\n",
      "Reorder this dataset alex_kovalev_standart_elbow_left True\n",
      "Number of moves: 72 | Dataset: anna_makarova_standart_elbow_left\n",
      "Reorder this dataset anna_makarova_standart_elbow_left True\n",
      "Number of moves: 62 | Dataset: artem_snailbox_standart_elbow_left\n",
      "Reorder this dataset artem_snailbox_standart_elbow_left True\n",
      "Number of moves: 144 | Dataset: matthew_antonov_standart_elbow_left\n",
      "Reorder this dataset matthew_antonov_standart_elbow_left True\n",
      "Number of moves: 144 | Dataset: misha_korobok_standart_elbow_left\n",
      "Reorder this dataset misha_korobok_standart_elbow_left True\n",
      "Number of moves: 71 | Dataset: nikita_snailbox_standart_elbow_left\n",
      "Reorder this dataset nikita_snailbox_standart_elbow_left True\n",
      "Number of moves: 144 | Dataset: petya_chizhov_standart_elbow_left\n",
      "Reorder this dataset petya_chizhov_standart_elbow_left True\n",
      "Number of moves: 12 | Dataset: polina_maksimova_standart_elbow_left\n",
      "Reorder this dataset polina_maksimova_standart_elbow_left True\n",
      "Number of moves: 144 | Dataset: sema_duplin_standart_elbow_left\n",
      "Reorder this dataset sema_duplin_standart_elbow_left True\n",
      "Number of moves: 136 | Dataset: alex_kovalev_standart_elbow_right\n",
      "Number of moves: 69 | Dataset: andrew_snailbox_standart_elbow_right\n",
      "Number of moves: 132 | Dataset: anna_makarova_standart_elbow_right\n",
      "Number of moves: 67 | Dataset: artem_snailbox_standart_elbow_right\n",
      "Number of moves: 68 | Dataset: matthew_antonov_standart_elbow_right\n",
      "Number of moves: 72 | Dataset: matvey_gorbenko_standart_elbow_right\n",
      "Number of moves: 144 | Dataset: misha_korobok_standart_elbow_right\n",
      "Number of moves: 55 | Dataset: nikita_snailbox_standart_elbow_right\n",
      "Number of moves: 142 | Dataset: petya_chizhov_standart_elbow_right\n",
      "Number of moves: 54 | Dataset: polina_maksimova_standart_elbow_right\n",
      "Number of moves: 139 | Dataset: sema_duplin_standart_elbow_right\n",
      "Number of trainining sessions: 22\n",
      "Number of validation sessions: 1\n",
      "Size of the input (8, 256) || Size of the output (20, 32)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = r\"C:\\Users\\1sabe\\OneDrive\\Documents\\Projects\\Sabeehs Pioneer\\dataset_v2_blocks\\dataset_v2_blocks\"\n",
    "def count_parameters(model): \n",
    "    n_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    n_total = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total: {n_total/1e6:.2f}M, Trainable: {n_trainable/1e6:.2f}M\")\n",
    "    return n_total, n_trainable\n",
    "\n",
    "\n",
    "    \n",
    "## Data preparation\n",
    "transform = get_default_transform(train_config.p_augs)\n",
    "data_paths = dict(datasets=[DATA_PATH],\n",
    "                    hand_type = ['left', 'right'], # [left, 'right']\n",
    "                    human_type = ['health', 'amputant'], # [amputant, 'health']\n",
    "                    test_dataset_list = ['fedya_tropin_standart_elbow_left'])\n",
    "data_config = creating_dataset.DataConfig(**data_paths)\n",
    "train_dataset, test_dataset = creating_dataset.get_datasets(data_config, transform=transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the model\n",
    "As you can see below, the model has a number of hyperparameters specifying its architecture and parameters. These are the parameters used to generate the baseline predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 4210788\n",
      "Total: 4.21M, Trainable: 4.21M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4210788, 4210788)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = hvatnet.Config(n_electrodes=8, n_channels_out=20,\n",
    "                            n_res_blocks=3, n_blocks_per_layer=3,\n",
    "                            n_filters=128, kernel_size=3,\n",
    "                            strides=(2, 2, 2), dilation=2, \n",
    "                            small_strides = (2, 2))\n",
    "model = hvatnet.HVATNetv3(model_config)\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the predictions are downsampled at 25Hz from the data originally recorded at 200Hz. The `hvatnet` model used here, automatically and correctly downsamples the data during predictions. Make sure that your model's oputput is also downsampled!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (8, 256), Y shape: (20, 32)\n",
      "Predictions shape: (20, 32)\n"
     ]
    }
   ],
   "source": [
    "X, Y = train_dataset[0]\n",
    "print(f\"X shape: {X.shape}, Y shape: {Y.shape}\")\n",
    "\n",
    "Y_hat = model(torch.tensor(X).unsqueeze(0)).squeeze().detach().numpy()\n",
    "\n",
    "print(f\"Predictions shape: {Y_hat.shape}\")\n",
    "\n",
    "assert Y.shape == Y_hat.shape, \"Predictions have the wrong shape!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code trains the baseline model using training code defined in `utils`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed initialization of scheduler\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 150: 0.28791099786758423\n",
      "val loss: 0.3293892741203308\n",
      "saved model:  step_150_loss_0.3294.safetensors\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 300: 0.27970874309539795\n",
      "val loss: 0.3400385081768036\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 450: 0.2602197527885437\n",
      "val loss: 0.36455726623535156\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 600: 0.22306756675243378\n",
      "val loss: 0.3570087254047394\n",
      "\n",
      "\n",
      "****************************************************************************************************************************************"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m run_train_model(model, (train_dataset, test_dataset), train_config, device)\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\BCI_ALVI_challenge\\utils\\train.py:113\u001b[0m, in \u001b[0;36mrun_train_model\u001b[1;34m(model, datasets, config, device)\u001b[0m\n\u001b[0;32m    111\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    112\u001b[0m loss, _ \u001b[38;5;241m=\u001b[39m model(inputs, labels)\n\u001b[1;32m--> 113\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mgrad_clip:\n\u001b[0;32m    116\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), config\u001b[38;5;241m.\u001b[39mgrad_clip)\n",
      "File \u001b[1;32mc:\\Users\\1sabe\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    527\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\1sabe\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m _engine_run_backward(\n\u001b[0;32m    268\u001b[0m     tensors,\n\u001b[0;32m    269\u001b[0m     grad_tensors_,\n\u001b[0;32m    270\u001b[0m     retain_graph,\n\u001b[0;32m    271\u001b[0m     create_graph,\n\u001b[0;32m    272\u001b[0m     inputs,\n\u001b[0;32m    273\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\1sabe\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "run_train_model(model, (train_dataset, test_dataset), train_config, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
